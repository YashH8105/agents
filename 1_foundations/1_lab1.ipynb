{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the start of your adventure in Agentic AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Are you ready for action??</h2>\n",
    "            <span style=\"color:#ff7800;\">Have you completed all the setup steps in the <a href=\"../setup/\">setup</a> folder?<br/>\n",
    "            Have you read the <a href=\"../README.md\">README</a>? Many common questions are answered here!<br/>\n",
    "            Have you checked out the guides in the <a href=\"../guides/01_intro.ipynb\">guides</a> folder?<br/>\n",
    "            Well in that case, you're ready!!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">This code is a live resource - keep an eye out for my updates</h2>\n",
    "            <span style=\"color:#00bfff;\">I push updates regularly. As people ask questions or have problems, I add more examples and improve explanations. As a result, the code below might not be identical to the videos, as I've added more steps and better comments. Consider this like an interactive book that accompanies the lectures.<br/><br/>\n",
    "            I try to send emails regularly with important updates related to the course. You can find this in the 'Announcements' section of Udemy in the left sidebar. You can also choose to receive my emails via your Notification Settings in Udemy. I'm respectful of your inbox and always try to add value with my emails!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And please do remember to contact me if I can help\n",
    "\n",
    "And I love to connect: https://www.linkedin.com/in/eddonner/\n",
    "\n",
    "\n",
    "### New to Notebooks like this one? Head over to the guides folder!\n",
    "\n",
    "Just to check you've already added the Python and Jupyter extensions to Cursor, if not already installed:\n",
    "- Open extensions (View >> extensions)\n",
    "- Search for python, and when the results show, click on the ms-python one, and Install it if not already installed\n",
    "- Search for jupyter, and when the results show, click on the Microsoft one, and Install it if not already installed  \n",
    "Then View >> Explorer to bring back the File Explorer.\n",
    "\n",
    "And then:\n",
    "1. Click where it says \"Select Kernel\" near the top right, and select the option called `.venv (Python 3.12.9)` or similar, which should be the first choice or the most prominent choice. You may need to choose \"Python Environments\" first.\n",
    "2. Click in each \"cell\" below, starting with the cell immediately below this text, and press Shift+Enter to run\n",
    "3. Enjoy!\n",
    "\n",
    "After you click \"Select Kernel\", if there is no option like `.venv (Python 3.12.9)` then please do the following:  \n",
    "1. On Mac: From the Cursor menu, choose Settings >> VS Code Settings (NOTE: be sure to select `VSCode Settings` not `Cursor Settings`);  \n",
    "On Windows PC: From the File menu, choose Preferences >> VS Code Settings(NOTE: be sure to select `VSCode Settings` not `Cursor Settings`)  \n",
    "2. In the Settings search bar, type \"venv\"  \n",
    "3. In the field \"Path to folder with a list of Virtual Environments\" put the path to the project root, like C:\\Users\\username\\projects\\agents (on a Windows PC) or /Users/username/projects/agents (on Mac or Linux).  \n",
    "And then try again.\n",
    "\n",
    "Having problems with missing Python versions in that list? Have you ever used Anaconda before? It might be interferring. Quit Cursor, bring up a new command line, and make sure that your Anaconda environment is deactivated:    \n",
    "`conda deactivate`  \n",
    "And if you still have any problems with conda and python versions, it's possible that you will need to run this too:  \n",
    "`conda config --set auto_activate_base false`  \n",
    "and then from within the Agents directory, you should be able to run `uv python list` and see the Python 3.12 version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's do an import. If you get an Import Error, double check that your Kernel is correct..\n",
    "\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next it's time to load the API keys into environment variables\n",
    "# If this returns false, see the next cell!\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait, did that just output `False`??\n",
    "\n",
    "If so, the most common reason is that you didn't save your `.env` file after adding the key! Be sure to have saved.\n",
    "\n",
    "Also, make sure the `.env` file is named precisely `.env` and is in the project root directory (`agents`)\n",
    "\n",
    "By the way, your `.env` file should have a stop symbol next to it in Cursor on the left, and that's actually a good thing: that's Cursor saying to you, \"hey, I realize this is a file filled with secret information, and I'm not going to send it to an external AI to suggest changes, because your keys should not be shown to anyone else.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Final reminders</h2>\n",
    "            <span style=\"color:#ff7800;\">1. If you're not confident about Environment Variables or Web Endpoints / APIs, please read Topics 3 and 5 in this <a href=\"../guides/04_technical_foundations.ipynb\">technical foundations guide</a>.<br/>\n",
    "            2. If you want to use AIs other than OpenAI, like Gemini, DeepSeek or Ollama (free), please see the first section in this <a href=\"../guides/09_ai_apis_and_ollama.ipynb\">AI APIs guide</a>.<br/>\n",
    "            3. If you ever get a Name Error in Python, you can always fix it immediately; see the last section of this <a href=\"../guides/06_python_foundations.ipynb\">Python Foundations guide</a> and follow both tutorials and exercises.<br/>\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the key - if you're not using OpenAI, check whichever key you're using! Ollama doesn't need a key.\n",
    "\n",
    "import os\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set - please head to the troubleshooting guide in the setup folder\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now - the all important import statement\n",
    "# If you get an import error - head over to troubleshooting in the Setup folder\n",
    "# Even for other LLM providers like Gemini, you still use this OpenAI import - see Guide 9 for why\n",
    "\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now we'll create an instance of the OpenAI class\n",
    "# If you're not sure what it means to create an instance of a class - head over to the guides folder (guide 6)!\n",
    "# If you get a NameError - head over to the guides folder (guide 6)to learn about NameErrors - always instantly fixable\n",
    "# If you're not using OpenAI, you just need to slightly modify this - precise instructions are in the AI APIs guide (guide 9)\n",
    "\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of messages in the familiar OpenAI format\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"What is 2+2?\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now call it! Any problems, head to the troubleshooting guide\n",
    "# This uses GPT 4.1 nano, the incredibly cheap model\n",
    "# The APIs guide (guide 9) has exact instructions for using even cheaper or free alternatives to OpenAI\n",
    "# If you get a NameError, head to the guides folder (guide 6) to learn about NameErrors - always instantly fixable\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now - let's ask for a question:\n",
    "\n",
    "question = \"Please propose a hard, challenging question to assess someone's IQ. Respond only with the question.\"\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ask it - this uses GPT 4.1 mini, still cheap but more powerful than nano\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "question = response.choices[0].message.content\n",
    "\n",
    "print(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# form a new messages list\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask it again\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "answer = response.choices[0].message.content\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(answer))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulationsssss!\n",
    "\n",
    "That was a small, simple step in the direction of Agentic AI, with your new environment!\n",
    "\n",
    "Next time things get more interesting..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercise</h2>\n",
    "            <span style=\"color:#ff7800;\">Now try this commercial application:<br/>\n",
    "            First ask the LLM to pick a business area that might be worth exploring for an Agentic AI opportunity.<br/>\n",
    "            Then ask the LLM to present a pain-point in that industry - something challenging that might be ripe for an Agentic solution.<br/>\n",
    "            Finally have 3 third LLM call propose the Agentic AI solution. <br/>\n",
    "            We will cover this at up-coming labs, so don't worry if you're unsure.. just give it a try!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1928229981.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mollama run llama3.2\u001b[39m\n           ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "ollama run llama3.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ollama' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openai'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m get_ipython().system(\u001b[33m'\u001b[39m\u001b[33mollama pull llama3.2\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[32m      5\u001b[39m OLLAMA_BASE_URL = \u001b[33m\"\u001b[39m\u001b[33mhttp://localhost:11434/v1\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      6\u001b[39m ollama = OpenAI(base_url=OLLAMA_BASE_URL, api_key=\u001b[33m\"\u001b[39m\u001b[33manything\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'openai'"
     ]
    }
   ],
   "source": [
    "!ollama pull llama3.2\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
    "ollama = OpenAI(base_url=OLLAMA_BASE_URL, api_key=\"anything\")\n",
    "response = ollama.chat.completions.create(model=\"llama3.2\", messages=[{\"role\":\"user\", \"content\": \"what is 2+2?\"}])\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Using cached openai-2.21.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Using cached anyio-4.12.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.10.0 (from openai)\n",
      "  Using cached jiter-0.13.0-cp312-cp312-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Using cached pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
      "Collecting sniffio (from openai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Using cached tqdm-4.67.3-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting typing-extensions<5,>=4.11 (from openai)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting idna>=2.8 (from anyio<5,>=3.5.0->openai)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting certifi (from httpx<1,>=0.23.0->openai)\n",
      "  Using cached certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached pydantic_core-2.41.5-cp312-cp312-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\Users\\PREETI\\OneDrive\\Desktop\\agents\\.venv\\Lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Using cached openai-2.21.0-py3-none-any.whl (1.1 MB)\n",
      "Using cached anyio-4.12.1-py3-none-any.whl (113 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached jiter-0.13.0-cp312-cp312-win_amd64.whl (205 kB)\n",
      "Using cached pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "Using cached pydantic_core-2.41.5-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached tqdm-4.67.3-py3-none-any.whl (78 kB)\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Using cached certifi-2026.1.4-py3-none-any.whl (152 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: typing-extensions, tqdm, sniffio, jiter, idna, h11, distro, certifi, annotated-types, typing-inspection, pydantic-core, httpcore, anyio, pydantic, httpx, openai\n",
      "\n",
      "   ----------------------------------------  0/16 [typing-extensions]\n",
      "   -- -------------------------------------  1/16 [tqdm]\n",
      "   -- -------------------------------------  1/16 [tqdm]\n",
      "   -- -------------------------------------  1/16 [tqdm]\n",
      "   -- -------------------------------------  1/16 [tqdm]\n",
      "   -- -------------------------------------  1/16 [tqdm]\n",
      "   -- -------------------------------------  1/16 [tqdm]\n",
      "   -- -------------------------------------  1/16 [tqdm]\n",
      "   -- -------------------------------------  1/16 [tqdm]\n",
      "   -- -------------------------------------  1/16 [tqdm]\n",
      "   -- -------------------------------------  1/16 [tqdm]\n",
      "   -- -------------------------------------  1/16 [tqdm]\n",
      "   -- -------------------------------------  1/16 [tqdm]\n",
      "   -- -------------------------------------  1/16 [tqdm]\n",
      "   ------- --------------------------------  3/16 [jiter]\n",
      "   ---------- -----------------------------  4/16 [idna]\n",
      "   ---------- -----------------------------  4/16 [idna]\n",
      "   ---------- -----------------------------  4/16 [idna]\n",
      "   ------------ ---------------------------  5/16 [h11]\n",
      "   ------------ ---------------------------  5/16 [h11]\n",
      "   ------------ ---------------------------  5/16 [h11]\n",
      "   ------------ ---------------------------  5/16 [h11]\n",
      "   ------------ ---------------------------  5/16 [h11]\n",
      "   ------------ ---------------------------  5/16 [h11]\n",
      "   ------------ ---------------------------  5/16 [h11]\n",
      "   --------------- ------------------------  6/16 [distro]\n",
      "   --------------- ------------------------  6/16 [distro]\n",
      "   --------------- ------------------------  6/16 [distro]\n",
      "   --------------- ------------------------  6/16 [distro]\n",
      "   -------------------- -------------------  8/16 [annotated-types]\n",
      "   ---------------------- -----------------  9/16 [typing-inspection]\n",
      "   ------------------------- -------------- 10/16 [pydantic-core]\n",
      "   ------------------------- -------------- 10/16 [pydantic-core]\n",
      "   --------------------------- ------------ 11/16 [httpcore]\n",
      "   --------------------------- ------------ 11/16 [httpcore]\n",
      "   --------------------------- ------------ 11/16 [httpcore]\n",
      "   --------------------------- ------------ 11/16 [httpcore]\n",
      "   --------------------------- ------------ 11/16 [httpcore]\n",
      "   --------------------------- ------------ 11/16 [httpcore]\n",
      "   --------------------------- ------------ 11/16 [httpcore]\n",
      "   --------------------------- ------------ 11/16 [httpcore]\n",
      "   --------------------------- ------------ 11/16 [httpcore]\n",
      "   --------------------------- ------------ 11/16 [httpcore]\n",
      "   --------------------------- ------------ 11/16 [httpcore]\n",
      "   ------------------------------ --------- 12/16 [anyio]\n",
      "   ------------------------------ --------- 12/16 [anyio]\n",
      "   ------------------------------ --------- 12/16 [anyio]\n",
      "   ------------------------------ --------- 12/16 [anyio]\n",
      "   ------------------------------ --------- 12/16 [anyio]\n",
      "   ------------------------------ --------- 12/16 [anyio]\n",
      "   ------------------------------ --------- 12/16 [anyio]\n",
      "   ------------------------------ --------- 12/16 [anyio]\n",
      "   ------------------------------ --------- 12/16 [anyio]\n",
      "   -------------------------------- ------- 13/16 [pydantic]\n",
      "   -------------------------------- ------- 13/16 [pydantic]\n",
      "   -------------------------------- ------- 13/16 [pydantic]\n",
      "   -------------------------------- ------- 13/16 [pydantic]\n",
      "   -------------------------------- ------- 13/16 [pydantic]\n",
      "   -------------------------------- ------- 13/16 [pydantic]\n",
      "   -------------------------------- ------- 13/16 [pydantic]\n",
      "   -------------------------------- ------- 13/16 [pydantic]\n",
      "   -------------------------------- ------- 13/16 [pydantic]\n",
      "   -------------------------------- ------- 13/16 [pydantic]\n",
      "   -------------------------------- ------- 13/16 [pydantic]\n",
      "   -------------------------------- ------- 13/16 [pydantic]\n",
      "   -------------------------------- ------- 13/16 [pydantic]\n",
      "   -------------------------------- ------- 13/16 [pydantic]\n",
      "   -------------------------------- ------- 13/16 [pydantic]\n",
      "   -------------------------------- ------- 13/16 [pydantic]\n",
      "   -------------------------------- ------- 13/16 [pydantic]\n",
      "   -------------------------------- ------- 13/16 [pydantic]\n",
      "   -------------------------------- ------- 13/16 [pydantic]\n",
      "   -------------------------------- ------- 13/16 [pydantic]\n",
      "   -------------------------------- ------- 13/16 [pydantic]\n",
      "   -------------------------------- ------- 13/16 [pydantic]\n",
      "   -------------------------------- ------- 13/16 [pydantic]\n",
      "   -------------------------------- ------- 13/16 [pydantic]\n",
      "   -------------------------------- ------- 13/16 [pydantic]\n",
      "   -------------------------------- ------- 13/16 [pydantic]\n",
      "   -------------------------------- ------- 13/16 [pydantic]\n",
      "   -------------------------------- ------- 13/16 [pydantic]\n",
      "   -------------------------------- ------- 13/16 [pydantic]\n",
      "   -------------------------------- ------- 13/16 [pydantic]\n",
      "   -------------------------------- ------- 13/16 [pydantic]\n",
      "   -------------------------------- ------- 13/16 [pydantic]\n",
      "   -------------------------------- ------- 13/16 [pydantic]\n",
      "   -------------------------------- ------- 13/16 [pydantic]\n",
      "   -------------------------------- ------- 13/16 [pydantic]\n",
      "   -------------------------------- ------- 13/16 [pydantic]\n",
      "   ----------------------------------- ---- 14/16 [httpx]\n",
      "   ----------------------------------- ---- 14/16 [httpx]\n",
      "   ----------------------------------- ---- 14/16 [httpx]\n",
      "   ----------------------------------- ---- 14/16 [httpx]\n",
      "   ----------------------------------- ---- 14/16 [httpx]\n",
      "   ----------------------------------- ---- 14/16 [httpx]\n",
      "   ----------------------------------- ---- 14/16 [httpx]\n",
      "   ----------------------------------- ---- 14/16 [httpx]\n",
      "   ----------------------------------- ---- 14/16 [httpx]\n",
      "   ----------------------------------- ---- 14/16 [httpx]\n",
      "   ----------------------------------- ---- 14/16 [httpx]\n",
      "   ----------------------------------- ---- 14/16 [httpx]\n",
      "   ----------------------------------- ---- 14/16 [httpx]\n",
      "   ----------------------------------- ---- 14/16 [httpx]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ---------------------------------------- 16/16 [openai]\n",
      "\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.12.1 certifi-2026.1.4 distro-1.9.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.11 jiter-0.13.0 openai-2.21.0 pydantic-2.12.5 pydantic-core-2.41.5 sniffio-1.3.1 tqdm-4.67.3 typing-extensions-4.15.0 typing-inspection-0.4.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))': /simple/openai/\n"
     ]
    }
   ],
   "source": [
    "pip install openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ollama' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 + 2 = 4\n"
     ]
    }
   ],
   "source": [
    "!ollama pull llama3.2\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
    "ollama = OpenAI(base_url=OLLAMA_BASE_URL, api_key=\"anything\")\n",
    "response = ollama.chat.completions.create(model=\"llama3.2\", messages=[{\"role\":\"user\", \"content\": \"what is 2+2?\"}])\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 + 2 = 4.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
    "ollama = OpenAI(base_url=OLLAMA_BASE_URL, api_key=\"anything\")\n",
    "response = ollama.chat.completions.create(model=\"llama3.2\", messages=[{\"role\":\"user\", \"content\": \"what is 2+2?\"}])\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ollama' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
    "ollama = OpenAI(base_url=OLLAMA_BASE_URL, api_key=\"anything\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"pick an industry which might have some agentic ai exploring opportunity\"\n",
    "message = [{\"role\" : \"user\", \"content\" : question}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's consider the finance and banking industry, particularly in areas such as:\n",
      "\n",
      "1. Fraud detection and prevention\n",
      "2. Risk management\n",
      "3. Portfolio optimization\n",
      "4. Customer service and relationship building\n",
      "5. Compliance and regulatory analysis\n",
      "\n",
      "Here are a few potential directions for Agentic AI to explore opportunities in this industry:\n",
      "\n",
      "**Opportunity 1:** **Automated Financial Planning**\n",
      "\n",
      "Agentic AI can be used to develop personalized financial plans for individuals or organizations based on their specific needs, goals, and risk tolerance. By analyzing vast amounts of financial data, these systems can identify opportunities and risks, providing targeted recommendations.\n",
      "\n",
      "**Opportunity 2:** **Predictive Portfolio Management**\n",
      "\n",
      "Agentic AI can analyze large datasets to predict asset prices and optimal portfolio allocations. This would help institutions make data-driven decisions about their investments, minimizing losses and maximizing returns.\n",
      "\n",
      "**Opportunity 3:** **Chatbot Customer Service Platforms**\n",
      "\n",
      "Agentic AI-powered chatbots can be integrated into finance companies' customer service platforms, automating routine tasks and providing personalized advice on financial matters. These systems could handle an increasingly high volume of inquiries while reducing operational costs.\n",
      "\n",
      "**Opportunity 4:** **Risk Management Automation**\n",
      "\n",
      "Agentic AI can simulate real-world scenarios to analyze potential risks for banks and other financial institutions. By testing numerous \"what-if\" situations, these models help identify vulnerabilities before they become major problems, providing actionable insights for proactive risk management.\n",
      "\n",
      "**Opportunity 5:** **Regulatory Compliance Scanning**\n",
      "\n",
      "Agentic AI systems can scan regulations, policies, and industry guidelines in real-time to analyze how well organizations or specific entities are complying. This would allow institutions to rapidly detect non-compliance and take corrective action before problems arise.\n",
      "\n",
      "To further explore these possibilities, I could provide more case studies of financial institutions using these technologies, discuss potential technical requirements for implementation, or outline an actual roadmap for successful AI integration in the finance sector\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "response =ollama.chat.completions.create(\n",
    "    model=\"llama3.2\",\n",
    "    messages=message\n",
    ")\n",
    "\n",
    "answer = response.choices[0].message.content\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"now pick a pain point from the mentioned industry which can be solved by agentic ai \"\n",
    "message = [{\"role\" : \"user\", \"content\" : question}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's take the retail industry as an example. One potential pain point is:\n",
      "\n",
      "**Inventory management and forecasting**\n",
      "\n",
      "Retailers often struggle with predicting demand, managing inventory levels, and minimizing stockouts or overstocking. This can lead to significant costs, from holding excess inventory to losing sales due to product unavailability.\n",
      "\n",
      "Agentic AI (Autonomous AI) can help solve this pain point in several ways:\n",
      "\n",
      "1. **Predictive Demand Modeling**: Agentic AI algorithms can analyze historical sales data, seasonality patterns, and market trends to create accurate predictive models for demand forecasting.\n",
      "2. **Dynamic Inventory Optimization**: An agentic AI system can continuously monitor inventory levels, sales data, and external factors (e.g., weather, supply chain disruptions) to adjust inventory management strategies in real-time, minimizing stockouts and overstocking.\n",
      "3. **Decision Support Systems**: Agentic AI can provide retailers with actionable insights and recommendations for optimizing inventory decisions, such as identifying underperforming products or suggesting replenishment schedules for slow-moving items.\n",
      "\n",
      "By leveraging agentic AI, retailers can:\n",
      "\n",
      "* Improve inventory accuracy and availability\n",
      "* Reduce supply chain complexities and costs\n",
      "* Enhance customer satisfaction through better product assortment and timely restocking\n",
      "\n",
      "Some potential benefits of using agentic AI in retail inventory management include:\n",
      "\n",
      "* Reduced stockouts by 10-20% due to more accurate demand forecasting\n",
      "* Inventory holding costs reduced by 5-10%\n",
      "* Improved product availability, leading to increased customer satisfaction and loyalty\n",
      "* Enhanced supply chain visibility and control\n",
      "* Data-driven decision-making for improved profitability\n",
      "\n",
      "What do you think? Can agentic AI help solve this pain point in the retail industry?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response =ollama.chat.completions.create(\n",
    "    model=\"llama3.2\",\n",
    "    messages=message\n",
    ")\n",
    "\n",
    "answer2 = response.choices[0].message.content\n",
    "print(answer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"pick an industry which might have some agentic ai exploring opportunity\"\n",
    "message = [{\"role\" : \"user\", \"content\" : question}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's consider the film and television production industry. Here's why:\n",
      "\n",
      "1. **Scalability**: Film and TV productions involve a large number of stakeholders, including directors, writers, producers, actors, and crew members. Agentic AI can help streamline this process by automating tasks, such as scriptwriting, storyboarding, and casting.\n",
      "2. **Creativity**: One of the most exciting applications of agentic AI in film and TV production is in the realm of creative storytelling. AI algorithms can generate new ideas, develop plot twists, or even create entire scripts, based on patterns in existing films and TV shows.\n",
      "3. **Collaboration**: Agentic AI can facilitate collaboration between creative individuals by providing suggestions, feedback, and suggestions for improvement. For example, an AI-powered \"story coach\" could analyze a script and suggest alternative scenes, characters, or plot twists to enhance the story.\n",
      "4. **Logistics management**: With so many people involved in film and TV productions, logistics can become incredibly complex. Agentic AI can help with tasks like scheduling, budgeting, and resource allocation by optimizing workflows and automating repetitive processes.\n",
      "5. **Cost reduction**: By automating routine tasks and improving efficiency, agentic AI can help reduce costs associated with film and TV production, making it more accessible to independent filmmakers and studios alike.\n",
      "\n",
      "Some possible ways agentic AI might explore opportunities in this industry:\n",
      "\n",
      "1. **AI-generated scripts**: Develop an AI system that can generate high-quality screenplays based on patterns from successful films and TV shows.\n",
      "2. **Character development**: Create an AI-powered \"character analysis\" tool that helps writers develop complex, well-rounded characters.\n",
      "3. **Virtual production planning**: Develop a platform that uses agentic AI to plan film and TV productions, taking into account factors like location availability, crew requirements, and equipment needs.\n",
      "4. **Content recommendation**: Establish an AI-driven system that analyzes audience feedback, box office performance, and market trends to recommend potential projects for filmmakers and producers.\n",
      "\n",
      "By leveraging these opportunities, we can unlock the full potential of agentic AI in film and TV production, creating more compelling stories, efficient workflows, and accessible opportunities for creators.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response =ollama.chat.completions.create(\n",
    "    model=\"llama3.2\",\n",
    "    messages=message\n",
    ")\n",
    "\n",
    "question = response.choices[0].message.content\n",
    "print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
